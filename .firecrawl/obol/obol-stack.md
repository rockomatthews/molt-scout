[Skip to content](https://github.com/ObolNetwork/obol-stack#start-of-content)

You signed in with another tab or window. [Reload](https://github.com/ObolNetwork/obol-stack) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/ObolNetwork/obol-stack) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/ObolNetwork/obol-stack) to refresh your session.Dismiss alert

{{ message }}

[ObolNetwork](https://github.com/ObolNetwork)/ **[obol-stack](https://github.com/ObolNetwork/obol-stack)** Public

- [Notifications](https://github.com/login?return_to=%2FObolNetwork%2Fobol-stack) You must be signed in to change notification settings
- [Fork\\
0](https://github.com/login?return_to=%2FObolNetwork%2Fobol-stack)
- [Star\\
4](https://github.com/login?return_to=%2FObolNetwork%2Fobol-stack)


A Kubernetes-based Ethereum stack for running decentralised applications.


[obol.org/stack](https://obol.org/stack "https://obol.org/stack")

### License

[Apache-2.0 license](https://github.com/ObolNetwork/obol-stack/blob/main/LICENSE)

[4\\
stars](https://github.com/ObolNetwork/obol-stack/stargazers) [0\\
forks](https://github.com/ObolNetwork/obol-stack/forks) [Branches](https://github.com/ObolNetwork/obol-stack/branches) [Tags](https://github.com/ObolNetwork/obol-stack/tags) [Activity](https://github.com/ObolNetwork/obol-stack/activity)

[Star](https://github.com/login?return_to=%2FObolNetwork%2Fobol-stack)

[Notifications](https://github.com/login?return_to=%2FObolNetwork%2Fobol-stack) You must be signed in to change notification settings

# ObolNetwork/obol-stack

main

[**24** Branches](https://github.com/ObolNetwork/obol-stack/branches) [**12** Tags](https://github.com/ObolNetwork/obol-stack/tags)

[Go to Branches page](https://github.com/ObolNetwork/obol-stack/branches)[Go to Tags page](https://github.com/ObolNetwork/obol-stack/tags)

Go to file

Code

Open more actions menu

## Folders and files

| Name | Name | Last commit message | Last commit date |
| --- | --- | --- | --- |
| ## Latest commit<br>[![OisinKyne](https://avatars.githubusercontent.com/u/4981644?v=4&size=40)](https://github.com/OisinKyne)[OisinKyne](https://github.com/ObolNetwork/obol-stack/commits?author=OisinKyne)<br>[Improve startup on OSX (](https://github.com/ObolNetwork/obol-stack/commit/8d52b1f1cb8be52f40229a03ed7e58f0e948ff15) [#210](https://github.com/ObolNetwork/obol-stack/pull/210) [)](https://github.com/ObolNetwork/obol-stack/commit/8d52b1f1cb8be52f40229a03ed7e58f0e948ff15)<br>success<br>44 minutes agoFeb 23, 2026<br>[8d52b1f](https://github.com/ObolNetwork/obol-stack/commit/8d52b1f1cb8be52f40229a03ed7e58f0e948ff15) · 44 minutes agoFeb 23, 2026<br>## History<br>[281 Commits](https://github.com/ObolNetwork/obol-stack/commits/main/) <br>Open commit details<br>[View commit history for this file.](https://github.com/ObolNetwork/obol-stack/commits/main/) 281 Commits |
| [.agents/skills](https://github.com/ObolNetwork/obol-stack/tree/main/.agents/skills "This path skips through empty directories") | [.agents/skills](https://github.com/ObolNetwork/obol-stack/tree/main/.agents/skills "This path skips through empty directories") | [Openclaw skills (](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#197](https://github.com/ObolNetwork/obol-stack/pull/197) [)](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 3 days agoFeb 20, 2026 |
| [.claude/skills](https://github.com/ObolNetwork/obol-stack/tree/main/.claude/skills "This path skips through empty directories") | [.claude/skills](https://github.com/ObolNetwork/obol-stack/tree/main/.claude/skills "This path skips through empty directories") | [Release/pre flight and testing (](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#191](https://github.com/ObolNetwork/obol-stack/pull/191) [)](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 4 days agoFeb 19, 2026 |
| [.github/workflows](https://github.com/ObolNetwork/obol-stack/tree/main/.github/workflows "This path skips through empty directories") | [.github/workflows](https://github.com/ObolNetwork/obol-stack/tree/main/.github/workflows "This path skips through empty directories") | [Tighten gh actions (](https://github.com/ObolNetwork/obol-stack/commit/e663f2282e3f47cebc25b59b2cc6548ccd2ea799 "Tighten gh actions (#175)  * Tighten actions  * Update readme") [#175](https://github.com/ObolNetwork/obol-stack/pull/175) [)](https://github.com/ObolNetwork/obol-stack/commit/e663f2282e3f47cebc25b59b2cc6548ccd2ea799 "Tighten gh actions (#175)  * Tighten actions  * Update readme") | last weekFeb 17, 2026 |
| [.helix](https://github.com/ObolNetwork/obol-stack/tree/main/.helix ".helix") | [.helix](https://github.com/ObolNetwork/obol-stack/tree/main/.helix ".helix") | [basic nix flake for development](https://github.com/ObolNetwork/obol-stack/commit/48cd8ed13ec52f9548386d9fac9fc398df69a410 "basic nix flake for development") | 4 months agoOct 15, 2025 |
| [assets](https://github.com/ObolNetwork/obol-stack/tree/main/assets "assets") | [assets](https://github.com/ObolNetwork/obol-stack/tree/main/assets "assets") | [Update readme and claude.md (](https://github.com/ObolNetwork/obol-stack/commit/bccb51c5b7a11874d9ce47a6eb076dbfc4077db7 "Update readme and claude.md (#176)  * Update readme and claude.md  * Link docs  * Readding model -> llm commits for some reason (#177)  * Update README.md  Co-authored-by: Copilot <175728472+Copilot@users.noreply.github.com> Signed-off-by: Oisín Kyne <4981644+OisinKyne@users.noreply.github.com>  ---------  Signed-off-by: Oisín Kyne <4981644+OisinKyne@users.noreply.github.com> Co-authored-by: Copilot <175728472+Copilot@users.noreply.github.com>") [#176](https://github.com/ObolNetwork/obol-stack/pull/176) [)](https://github.com/ObolNetwork/obol-stack/commit/bccb51c5b7a11874d9ce47a6eb076dbfc4077db7 "Update readme and claude.md (#176)  * Update readme and claude.md  * Link docs  * Readding model -> llm commits for some reason (#177)  * Update README.md  Co-authored-by: Copilot <175728472+Copilot@users.noreply.github.com> Signed-off-by: Oisín Kyne <4981644+OisinKyne@users.noreply.github.com>  ---------  Signed-off-by: Oisín Kyne <4981644+OisinKyne@users.noreply.github.com> Co-authored-by: Copilot <175728472+Copilot@users.noreply.github.com>") | last weekFeb 17, 2026 |
| [cmd](https://github.com/ObolNetwork/obol-stack/tree/main/cmd "cmd") | [cmd](https://github.com/ObolNetwork/obol-stack/tree/main/cmd "cmd") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [docs](https://github.com/ObolNetwork/obol-stack/tree/main/docs "docs") | [docs](https://github.com/ObolNetwork/obol-stack/tree/main/docs "docs") | `obolclaw` [(](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") [#160](https://github.com/ObolNetwork/obol-stack/pull/160) [)](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") | last weekFeb 17, 2026 |
| [examples](https://github.com/ObolNetwork/obol-stack/tree/main/examples "examples") | [examples](https://github.com/ObolNetwork/obol-stack/tree/main/examples "examples") | [added persistence test for mounted pvc's](https://github.com/ObolNetwork/obol-stack/commit/dac9fdff1de9b5c167ea4de6de25fa1a55653141 "added persistence test for mounted pvc's") | 4 months agoOct 20, 2025 |
| [internal](https://github.com/ObolNetwork/obol-stack/tree/main/internal "internal") | [internal](https://github.com/ObolNetwork/obol-stack/tree/main/internal "internal") | [Improve startup on OSX (](https://github.com/ObolNetwork/obol-stack/commit/8d52b1f1cb8be52f40229a03ed7e58f0e948ff15 "Improve startup on OSX (#210)") [#210](https://github.com/ObolNetwork/obol-stack/pull/210) [)](https://github.com/ObolNetwork/obol-stack/commit/8d52b1f1cb8be52f40229a03ed7e58f0e948ff15 "Improve startup on OSX (#210)") | 44 minutes agoFeb 23, 2026 |
| [plans](https://github.com/ObolNetwork/obol-stack/tree/main/plans "plans") | [plans](https://github.com/ObolNetwork/obol-stack/tree/main/plans "plans") | [Openclaw skills (](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#197](https://github.com/ObolNetwork/obol-stack/pull/197) [)](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 3 days agoFeb 20, 2026 |
| [tests](https://github.com/ObolNetwork/obol-stack/tree/main/tests "tests") | [tests](https://github.com/ObolNetwork/obol-stack/tree/main/tests "tests") | [Openclaw skills (](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#197](https://github.com/ObolNetwork/obol-stack/pull/197) [)](https://github.com/ObolNetwork/obol-stack/commit/7585bfc53db60d43446f4496a7de568e4752e200 "Openclaw skills (#197)  * Intermediate commit of skills update  * docs update  * Getting closer  * Dynamic provider discovery from llmspy pod  Remove hardcoded provider map (anthropic/openai) and instead query the running llmspy pod's providers.json for env var names and available providers. This means any provider llmspy supports (zai, deepseek, google, mistral, etc.) works with `obol model setup` without code changes.  * Add unit tests for dynamic provider discovery logic  Extract pure functions (parseProviderEnvKey, parseAvailableProviders, buildProviderStatus, patchLLMsJSON) from kubectl-calling wrappers so they can be tested without a running cluster. 23 test cases covering parsing, status cross-referencing, JSON patching, and edge cases.  * Add Z.AI integration test for dynamic provider discovery  Adds TestIntegration_ZaiInference that exercises a provider NOT in the old hardcoded map, proving zero-code-change provider support. Uses glm-4-flash via llmspy routing with ZHIPU_API_KEY from .env.  * Add rich embedded skills and full test coverage  Replace the minimal ethereum skill with three production-ready skills: - obol-blockchain: Ethereum JSON-RPC via eRPC with rpc.py helper,   ERC-20 reference, contract addresses, ENS, gas estimation - obol-k8s: Kubernetes cluster diagnostics via ServiceAccount API   with kube.py helper for pod/service/event introspection - obol-dvt: Obol DVT cluster monitoring with API examples for   validator effectiveness, operator auditing, and exit coordination  Keeps the hello skill as-is for smoke testing.  Test coverage spans every layer of the skills pipeline: - Unit: embed discovery, copy, skip-existing, volume path, staging,   injection, no-op without skills - Integration: staging on sync, pod visibility via kubectl exec,   skills sync --from, idempotent re-sync, skill-through-inference   (agent references loaded skills), Python smoke tests piped into pod  * Update docs and developer skill for rich skills integration  Replace stale ethereum skill references with the four embedded skills (hello, obol-blockchain, obol-k8s, obol-dvt). Add standalone Skills section to README, update CLAUDE.md delivery flow and source file listings, and expand obol-stack-dev skill with skills system coverage.  * Fix Z.AI model ID and skills sync instance resolution in integration tests  - Use glm-5 instead of glm-4-flash (not in providers.json) - Pass explicit instance ID to skills sync when multiple instances exist  * Change the name on skills and test  * Polish  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 3 days agoFeb 20, 2026 |
| [worker](https://github.com/ObolNetwork/obol-stack/tree/main/worker "worker") | [worker](https://github.com/ObolNetwork/obol-stack/tree/main/worker "worker") | [feat: add cloudflare worker installer and update readme](https://github.com/ObolNetwork/obol-stack/commit/a1ec062ce940ec9c6cd2d247032db30e8e661829 "feat: add cloudflare worker installer and update readme") | 3 months agoNov 19, 2025 |
| [.env.example](https://github.com/ObolNetwork/obol-stack/blob/main/.env.example ".env.example") | [.env.example](https://github.com/ObolNetwork/obol-stack/blob/main/.env.example ".env.example") | [Release/pre flight and testing (](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#191](https://github.com/ObolNetwork/obol-stack/pull/191) [)](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 4 days agoFeb 19, 2026 |
| [.envrc](https://github.com/ObolNetwork/obol-stack/blob/main/.envrc ".envrc") | [.envrc](https://github.com/ObolNetwork/obol-stack/blob/main/.envrc ".envrc") | [envrc local setup](https://github.com/ObolNetwork/obol-stack/commit/ed4aebc58c23f4a98c7567913dea2097a7abd5b2 "envrc local setup") | 4 months agoOct 15, 2025 |
| [.envrc.local.example](https://github.com/ObolNetwork/obol-stack/blob/main/.envrc.local.example ".envrc.local.example") | [.envrc.local.example](https://github.com/ObolNetwork/obol-stack/blob/main/.envrc.local.example ".envrc.local.example") | [envrc local setup](https://github.com/ObolNetwork/obol-stack/commit/ed4aebc58c23f4a98c7567913dea2097a7abd5b2 "envrc local setup") | 4 months agoOct 15, 2025 |
| [.gitignore](https://github.com/ObolNetwork/obol-stack/blob/main/.gitignore ".gitignore") | [.gitignore](https://github.com/ObolNetwork/obol-stack/blob/main/.gitignore ".gitignore") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [CLAUDE.md](https://github.com/ObolNetwork/obol-stack/blob/main/CLAUDE.md "CLAUDE.md") | [CLAUDE.md](https://github.com/ObolNetwork/obol-stack/blob/main/CLAUDE.md "CLAUDE.md") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [CONTRIBUTING.md](https://github.com/ObolNetwork/obol-stack/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | [CONTRIBUTING.md](https://github.com/ObolNetwork/obol-stack/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | [feat(helm): add Helios Ethereum light client chart](https://github.com/ObolNetwork/obol-stack/commit/669afd9fa6a45e359aae3c8c94cc70caafdf7322 "feat(helm): add Helios Ethereum light client chart  Implements a Kubernetes Helm chart for the Helios Ethereum light client with StatefulSet support, configurable execution RPC, and custom health checks. This chart enables running Helios as a reliable Ethereum RPC provider in a Kubernetes environment.") | 11 months agoMar 19, 2025 |
| [Dockerfile.inference-gateway](https://github.com/ObolNetwork/obol-stack/blob/main/Dockerfile.inference-gateway "Dockerfile.inference-gateway") | [Dockerfile.inference-gateway](https://github.com/ObolNetwork/obol-stack/blob/main/Dockerfile.inference-gateway "Dockerfile.inference-gateway") | `obolclaw` [(](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") [#160](https://github.com/ObolNetwork/obol-stack/pull/160) [)](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") | last weekFeb 17, 2026 |
| [LICENSE](https://github.com/ObolNetwork/obol-stack/blob/main/LICENSE "LICENSE") | [LICENSE](https://github.com/ObolNetwork/obol-stack/blob/main/LICENSE "LICENSE") | [Take a first pass at the readme too](https://github.com/ObolNetwork/obol-stack/commit/e1a9867f8b34fcfea80563ce65d5c36706cf4dd9 "Take a first pass at the readme too") | 10 months agoApr 10, 2025 |
| [README.md](https://github.com/ObolNetwork/obol-stack/blob/main/README.md "README.md") | [README.md](https://github.com/ObolNetwork/obol-stack/blob/main/README.md "README.md") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [VERSION](https://github.com/ObolNetwork/obol-stack/blob/main/VERSION "VERSION") | [VERSION](https://github.com/ObolNetwork/obol-stack/blob/main/VERSION "VERSION") | [cleaned up justfile with build and versioning](https://github.com/ObolNetwork/obol-stack/commit/d3066378367d936195dd5ab802370dc2f1cb2d7d "cleaned up justfile with build and versioning") | 4 months agoOct 20, 2025 |
| [flake.lock](https://github.com/ObolNetwork/obol-stack/blob/main/flake.lock "flake.lock") | [flake.lock](https://github.com/ObolNetwork/obol-stack/blob/main/flake.lock "flake.lock") | [basic nix flake for development](https://github.com/ObolNetwork/obol-stack/commit/48cd8ed13ec52f9548386d9fac9fc398df69a410 "basic nix flake for development") | 4 months agoOct 15, 2025 |
| [flake.nix](https://github.com/ObolNetwork/obol-stack/blob/main/flake.nix "flake.nix") | [flake.nix](https://github.com/ObolNetwork/obol-stack/blob/main/flake.nix "flake.nix") | [obolup.sh improvement (](https://github.com/ObolNetwork/obol-stack/commit/761886e2295e1c81ff1783571d29444ae5d3b005 "obolup.sh improvement (#80)  * update  * add endpoints") [#80](https://github.com/ObolNetwork/obol-stack/pull/80) [)](https://github.com/ObolNetwork/obol-stack/commit/761886e2295e1c81ff1783571d29444ae5d3b005 "obolup.sh improvement (#80)  * update  * add endpoints") | 3 months agoNov 6, 2025 |
| [go.mod](https://github.com/ObolNetwork/obol-stack/blob/main/go.mod "go.mod") | [go.mod](https://github.com/ObolNetwork/obol-stack/blob/main/go.mod "go.mod") | [fix(deps): bump golang.org/x/crypto to v0.45.0 (](https://github.com/ObolNetwork/obol-stack/commit/7a127302e2c5121c21fcf343dc15554890ab708e "fix(deps): bump golang.org/x/crypto to v0.45.0 (#193)  Fixes two moderate Dependabot vulnerabilities: - CVE: ssh allows unbounded memory consumption - CVE: ssh/agent panic on malformed message (out-of-bounds read)  Also bumps transitive deps: x/sys v0.38.0, x/term v0.37.0.") [#193](https://github.com/ObolNetwork/obol-stack/pull/193) [)](https://github.com/ObolNetwork/obol-stack/commit/7a127302e2c5121c21fcf343dc15554890ab708e "fix(deps): bump golang.org/x/crypto to v0.45.0 (#193)  Fixes two moderate Dependabot vulnerabilities: - CVE: ssh allows unbounded memory consumption - CVE: ssh/agent panic on malformed message (out-of-bounds read)  Also bumps transitive deps: x/sys v0.38.0, x/term v0.37.0.") | 4 days agoFeb 19, 2026 |
| [go.sum](https://github.com/ObolNetwork/obol-stack/blob/main/go.sum "go.sum") | [go.sum](https://github.com/ObolNetwork/obol-stack/blob/main/go.sum "go.sum") | [fix(deps): bump golang.org/x/crypto to v0.45.0 (](https://github.com/ObolNetwork/obol-stack/commit/7a127302e2c5121c21fcf343dc15554890ab708e "fix(deps): bump golang.org/x/crypto to v0.45.0 (#193)  Fixes two moderate Dependabot vulnerabilities: - CVE: ssh allows unbounded memory consumption - CVE: ssh/agent panic on malformed message (out-of-bounds read)  Also bumps transitive deps: x/sys v0.38.0, x/term v0.37.0.") [#193](https://github.com/ObolNetwork/obol-stack/pull/193) [)](https://github.com/ObolNetwork/obol-stack/commit/7a127302e2c5121c21fcf343dc15554890ab708e "fix(deps): bump golang.org/x/crypto to v0.45.0 (#193)  Fixes two moderate Dependabot vulnerabilities: - CVE: ssh allows unbounded memory consumption - CVE: ssh/agent panic on malformed message (out-of-bounds read)  Also bumps transitive deps: x/sys v0.38.0, x/term v0.37.0.") | 4 days agoFeb 19, 2026 |
| [justfile](https://github.com/ObolNetwork/obol-stack/blob/main/justfile "justfile") | [justfile](https://github.com/ObolNetwork/obol-stack/blob/main/justfile "justfile") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [notes.md](https://github.com/ObolNetwork/obol-stack/blob/main/notes.md "notes.md") | [notes.md](https://github.com/ObolNetwork/obol-stack/blob/main/notes.md "notes.md") | `obolclaw` [(](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") [#160](https://github.com/ObolNetwork/obol-stack/pull/160) [)](https://github.com/ObolNetwork/obol-stack/commit/4db6fabca99affbdea91ad05f6d4b63c27da0809 "`obolclaw` (#160)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat: persist Cloudflare Tunnel hostname via login + loosen Gateway hostnames  * chore: bump cloudflared to 2026.1.2  * feat(inference): add x402 pay-per-inference gateway (Phase 1)  Introduce the inference marketplace foundation: an x402-enabled reverse proxy that wraps any OpenAI-compatible inference service with USDC micropayments via the x402 protocol.  Components: - internal/inference/gateway.go: net/http reverse proxy with x402 middleware - cmd/inference-gateway/: standalone binary for containerisation - cmd/obol/inference.go: `obol inference serve` CLI command - internal/embed/networks/inference/: helmfile network template deploying   Ollama + gateway + HTTPRoute (auto-discovered by existing CLI) - Dockerfile.inference-gateway: distroless multi-stage build  Provider: obol network install inference --wallet-address 0x... --model llama3.2:3b Consumer: POST /v1/chat/completions with X-PAYMENT header (USDC on Base)  * fix(infra): fix helmfile template errors in defaults deployment  - Remove unused $publicDomain variable from helmfile.yaml (caused   Helmfile v1 gotmpl pre-processing to fail on .Values.* references) - Fix eRPC secretEnv: chart expects plain strings, not secretKeyRef   maps; move OBOL_OAUTH_TOKEN to extraEnv with valueFrom - Fix obol-frontend escaped quotes in gotmpl (invalid \\\" in operand)  * refactor(llm): remove in-cluster Ollama, proxy to host via ExternalName  Replace the in-cluster Ollama Deployment/PVC/Service with an ExternalName Service that routes ollama.llm.svc.cluster.local to the host machine's Ollama server. LLMSpy and all consumers use the stable cluster-internal DNS name; the ExternalName target is resolved during stack init via the {{OLLAMA_HOST}} placeholder:    k3d  → host.k3d.internal   k3s  → node gateway IP (future)  This avoids duplicating the model cache inside the cluster and leverages the host's GPU/VRAM for inference.  Also updates CopyDefaults to accept a replacements map, following the same pattern used for k3d.yaml placeholder resolution.  * fix(infra): disable obol-agent from default stack deployment  The obol-agent deployment in the agent namespace fails with ImagePullBackOff because its container image is not publicly accessible. Wrap the template in a Helm conditional (obolAgent.enabled) defaulting to false so it no longer deploys automatically. The manifest is preserved for future use — set obolAgent.enabled=true in the base chart values to re-enable.  * ci(openclaw): add Docker image build workflow with Renovate auto-bump  Add GitHub Actions workflow to build and publish the OpenClaw container image to ghcr.io/obolnetwork/openclaw from the upstream openclaw/openclaw repo at a pinned version. Renovate watches for new upstream releases and auto-opens PRs to bump the version file.  Closes #142  * ci(openclaw): temporarily add test branches to workflow triggers  Add integration-okr-1 and feat/openclaw-ci to push triggers for testing. Remove after verifying the workflow runs successfully — limit to main only.  * ci(openclaw): trigger workflow test run  * fix(ci): update Trivy and CodeQL action SHAs to latest  The pinned SHAs from charon-dkg-sidecar were stale and caused the security-scan job to fail at setup.  * ci(openclaw): re-trigger workflow to verify security scan fix  * chore(openclaw): bump version to v2026.2.9  * feat(openclaw): add OpenClaw CLI and Helm chart (#137)  * feat(openclaw): add OpenClaw CLI and embedded chart for Obol Stack  Adds `obol openclaw` subcommands to deploy and manage OpenClaw AI agent instances on the local k3d cluster. The chart is embedded via go:embed for development use; the canonical chart lives in ObolNetwork/helm-charts.  CLI commands:   openclaw up      - Create and deploy an instance   openclaw sync    - Re-deploy / update an existing instance   openclaw token   - Retrieve the gateway token   openclaw list    - List deployed instances   openclaw delete  - Remove an instance   openclaw skills  - Sync skills from a local directory  The embedded Helm chart supports:   - Pluggable model providers (Anthropic, OpenAI, Ollama)   - Chat channels (Telegram, Discord, Slack)   - Skills injection via ConfigMap + init container   - RBAC, Gateway API HTTPRoute, values schema validation  * feat(openclaw): integrate OpenClaw into stack setup with config import  OpenClaw is now deployed automatically as a default instance during `obol stack up`. Adds ~/.openclaw/openclaw.json detection and import, interactive provider selection for direct CLI usage, and idempotent re-sync behavior for the default instance.  * fix: resolve CRD conflicts, OpenClaw command, HTTPRoute spec, and KUBECONFIG propagation  - Remove gateway-api-crds presync hook; Traefik v38+ manages its own CRDs - Fix Ethereum HTTPRoute: use single PathPrefix match (Gateway API spec) - Fix OpenClaw chart command to match upstream Dockerfile (node openclaw.mjs) - Update OpenClaw image tag to match GHCR published format (no v prefix) - Add KUBECONFIG env to helmfile subprocess in stack.go (aligns with all other packages)  * feat(openclaw): detect and import existing ~/.openclaw workspace + bump to v2026.2.9  Auto-detect existing OpenClaw installations during `obol stack up` and `obol openclaw up`. When ~/.openclaw/ contains a workspace directory with personality files (SOUL.md, AGENTS.md, etc.), copies them into the pod's PVC after deployment. Auto-skips interactive provider prompts when an existing config with providers is detected.  Also bumps the chart image to v2026.2.9 to match the CI-published image.  * feat(openclaw): add setup wizard and dashboard commands  Add `obol openclaw setup <id>` which port-forwards to the deployed gateway and runs the native OpenClaw onboard wizard via PTY. The wizard provides the full onboarding experience (personality, channels, skills, providers) against the running k8s instance.  Add `obol openclaw dashboard <id>` which port-forwards and opens the web dashboard in the browser with auto-injected gateway token.  Implementation details: - Port-forward lifecycle manager with auto-port selection - PTY-based wizard with raw terminal mode for @clack/prompts support - Sliding-window marker detection to exit cleanly when wizard completes - Proper PTY shutdown sequence (close master -> kill -> wait) to avoid   hang caused by stdin copy goroutine blocking cmd.Wait() - Refactored Token() into reusable getToken() helper - findOpenClawBinary() searches PATH then cfg.BinDir with install hints - obolup.sh gains install_openclaw() for npm-based binary management  * feat(llm,openclaw): llmspy universal proxy + openclaw CLI passthrough  Route all cloud API traffic through llmspy as a universal gateway: - Add Anthropic/OpenAI providers to llm.yaml (ConfigMap + Secret + envFrom) - New `internal/llm` package with ConfigureLLMSpy() for imperative patching - New `obol llm configure` command for standalone provider setup - OpenClaw overlay routes through llmspy:8000/v1 instead of direct cloud APIs - Bump llmspy image to obol fork rc.2 (fixes SQLite startup race)  Add `obol openclaw cli <id> -- <args>` passthrough: - Remote-capable commands (gateway, acp, browser, logs) via port-forward - Local-only commands (doctor, models, config) via kubectl exec - Replace PTY-based setup wizard with non-interactive helmfile sync flow - Remove creack/pty and golang.org/x/term dependencies  * fix(openclaw): rename up→onboard, fix api field and macOS host resolution  - Rename `obol openclaw up` to `obol openclaw onboard` - Set api: \"openai-completions\" in llmspy-routed overlay (fixes   \"No API provider registered for api: undefined\" in OpenClaw) - Use host.docker.internal on macOS for Ollama ExternalName service   (host.k3d.internal doesn't resolve on Docker Desktop)  * feat(openclaw): detect Ollama availability before offering it in setup wizard  SetupDefault() now probes the host Ollama endpoint before deploying with Ollama defaults — skips gracefully when unreachable so users without Ollama can configure a cloud provider later via `obol openclaw setup`. interactiveSetup() dynamically shows a 3-option menu (Ollama/OpenAI/ Anthropic) when Ollama is detected, or a 2-option menu (OpenAI/Anthropic) when it isn't.  * docs: add LLM configuration architecture to CLAUDE.md  Document the two-tier model: global llmspy gateway (cluster-wide keys and provider routing) vs per-instance OpenClaw config (overlay values pointing at llmspy or directly at cloud APIs). Includes data flow diagram, summary table, and key source files reference.  * fix(openclaw): update model defaults and improve chart documentation  Update Anthropic models to include Opus 4.6, replace retiring GPT-4o with GPT-5.2, add next-step guidance to NOTES.txt, and clarify gateway token and skills injection comments per CTO review feedback.  * fix(openclaw): sync chart hardening from helm-charts  Sync _helpers.tpl, validate.yaml, and values.yaml comments to match the helm-charts repo. Key changes: - Remove randAlphaNum gateway token fallback (require explicit value) - Add validation: gateway token required for token auth mode - Add validation: RBAC requires serviceAccount.name when create=false - Add validation: initJob requires persistence.enabled=true - Align provider and gateway token comments  * feat(dns): add wildcard DNS resolver for *.obol.stack  Add a local dnsmasq-based DNS resolver that enables wildcard hostname resolution for per-instance routing (e.g., openclaw-myid.obol.stack) without manual /etc/hosts entries.  - New internal/dns package: manages dnsmasq Docker container on port 5553 - macOS: auto-configures /etc/resolver/obol.stack (requires sudo once) - Linux: prints manual DNS configuration instructions - stack up: starts DNS resolver (idempotent, non-fatal on failure) - stack purge: stops DNS resolver and removes system resolver config - stack down: leaves DNS resolver running (cheap, persists across restarts)  Closes #150  * feat(dns): add Linux support and fix llmspy image tag  DNS resolver: add systemd-resolved integration for Linux. On Linux, dnsmasq binds to 127.0.0.2:53 (avoids systemd-resolved's stub on 127.0.0.53:53) and a resolved.conf.d drop-in forwards *.obol.stack queries. On macOS, behavior is unchanged (port 5553 + /etc/resolver).  Also fixes dnsmasq startup with --conf-file=/dev/null to ignore Alpine's default config which enables local-service (rejects queries from Docker bridge network).  Fix llmspy image tag: 3.0.32-obol.1-rc.2 does not exist on GHCR, corrected to 3.0.32-obol.1-rc.1.  * refactor(openclaw): replace embedded chart with remote obol/openclaw Helm repo (#145)  Switch from bundling the OpenClaw Helm chart in the Go binary via //go:embed to referencing obol/openclaw from the published Helm repo, matching the pattern used by Helios and Aztec networks.  Changes: - generateHelmfile() now emits chart: obol/openclaw with version pin - Remove copyEmbeddedChart() and all chart/values.yaml copy logic - Remove //go:embed directive, chartFS variable, and embed/io/fs imports - Delete internal/openclaw/chart/ (chart lives in helm-charts repo) - Deployment directory simplified to helmfile.yaml + values-obol.yaml - Setup() regenerates helmfile on each run to pick up version bumps  Depends on helm-charts PR #183 being merged and chart published.  * cleanup(network): remove Helios light client network (#146)  Helios is no longer part of the Obol Stack network lineup. Remove the embedded network definition, frontend env var, and all documentation references.  * test(openclaw): add import pipeline tests and fix silent failures (#147)  Add comprehensive unit tests for the OpenClaw config import pipeline (25 test cases covering DetectExistingConfig, TranslateToOverlayYAML, workspace detection, and helper functions). Refactor DetectExistingConfig for testability by extracting detectExistingConfigAt(home).  Fix silent failures: warn when env-var API keys are skipped, when unknown API types are sanitized, when workspace has no marker files, and when DetectExistingConfig returns an error.  * fix(openclaw): add controlUi gateway settings for Traefik HTTP proxy (#153)  OpenClaw's control UI rejects WebSocket connections with \"1008: control ui requires HTTPS or localhost (secure context)\" when running behind Traefik over HTTP. This adds:  - Chart values and _helpers.tpl rendering for controlUi.allowInsecureAuth   and controlUi.dangerouslyDisableDeviceAuth gateway settings - trustedProxies chart value for reverse proxy IP allowlisting - Overlay generation injects controlUi settings for both imported and   fresh install paths - RBAC ClusterRole/ClusterRoleBinding for frontend OpenClaw instance   discovery (namespaces, pods, configmaps, secrets)  * fix(openclaw): rename virtual provider from \"ollama\" to \"llmspy\" for cloud model routing  OpenClaw requires provider/model format (e.g. \"llmspy/claude-sonnet-4-5-20250929\") for model resolution. Without a provider prefix, it hardcodes a fallback to the \"anthropic\" provider — which is disabled in the llmspy-routed overlay, causing chat requests to fail silently.  This renames the virtual provider used for cloud model routing from \"ollama\" to \"llmspy\", adds the proper provider prefix to AgentModel, and disables the default \"ollama\" provider when a cloud provider is selected. The default Ollama-only path is unchanged since it genuinely routes Ollama models.  * security(openclaw): remove dangerouslyDisableDeviceAuth, keep only allowInsecureAuth  The dangerouslyDisableDeviceAuth flag is completely redundant when running behind Traefik over HTTP: the browser's crypto.subtle API is unavailable in non-secure contexts (non-localhost HTTP), so the Control UI never sends device identity at all. Setting dangerouslyDisableDeviceAuth only matters when the browser IS in a secure context but you want to skip device auth — which doesn't apply to our Traefik proxy case.  allowInsecureAuth alone is sufficient: it allows the gateway to accept token-only authentication when device identity is absent. Token auth remains fully enforced — connections without a valid gateway token are still rejected.  Security analysis: - Token/password auth: still enforced (timing-safe comparison) - Origin check: still enforced (same-origin validation) - Device identity: naturally skipped (browser can't provide it on HTTP) - Risk in localhost k3d context: Low (no external attack surface) - OpenClaw security audit classification: critical (general), but   acceptable for local-only dev stack  Refs: plans/security-audit-controlui.md, plans/trustedproxies-analysis.md  * chore(llm): bump LLMSpy image to 3.0.32-obol.1-rc.4  Includes smart routing, streaming SSE passthrough, and db writer startup race fix.  * security(openclaw): stop logging sensitive APIKey field value in import  Remove the p.APIKey value from the env-var reference log message in DetectExistingConfig(). Although the code path only reaches here when the value is an env-var reference (e.g. ${ANTHROPIC_API_KEY}), CodeQL correctly flags it as clear-text logging of a sensitive field (go/ clear-text-logging). Omitting the value is a defense-in-depth fix that prevents accidental exposure if the guard condition ever changes.  * feat(erpc): switch upstream from nodecore to erpc.gcp.obol.tech  Replace the nodecore RPC upstream with Obol's internal rate-limited eRPC gateway (erpc.gcp.obol.tech). The upstream supports mainnet and hoodi only, so sepolia is removed from all eRPC and ethereum network configurations.  Basic Auth credential is intentionally embedded per CTO approval — the endpoint is rate-limited and serves as a convenience proxy for local stack users. Credential is extracted to a template variable with gitleaks:allow suppression.  * chore: switch default model from glm-4.7-flash to gpt-oss:120b-cloud  Replace all references to glm-4.7-flash with Ollama's cloud model gpt-oss:120b-cloud. Cloud models run on Ollama's cloud service, eliminating OOM risk on local machines.  * fix(openclaw): revert llmspy provider name to ollama for chart compatibility  The remote OpenClaw Helm chart only iterates hardcoded provider names (ollama, anthropic, openai). Using \"llmspy\" as the virtual provider name caused it to be silently dropped from the rendered config, breaking the Anthropic inference waterfall.  Revert to using \"ollama\" as the provider name — it still points at llmspy's URL (http://llmspy.llm.svc.cluster.local:8000/v1) with api: openai-completions, so all routing works correctly.  Found during pre-production validation.  * fix(llm): use llmspy image for init container with provider merge script  Replace busybox init container with the llmspy image itself, using a Python merge script that: 1. Copies llms.json from ConfigMap (controls enabled/disabled state) 2. Loads the full providers.json from the llmspy package (has model    definitions and npm package refs for Anthropic/OpenAI) 3. Merges ConfigMap overrides (Ollama endpoint, API key refs)  Also remove \"models\": {} and \"all_models\": true from cloud providers in the ConfigMap — these crash llmspy since only Ollama has a load_models() implementation. Add \"npm\" field for Anthropic/OpenAI.  Found during pre-production Anthropic integration validation.  * fix(obolup): auto-start Docker daemon on Linux (snap + systemd)  When Docker is installed but the daemon isn't running, obolup now attempts to start it automatically: 1. Try systemd (apt/yum installs): sudo systemctl start docker 2. Try snap: sudo snap start docker  If auto-start fails, the error message now shows both systemd and snap commands instead of only systemctl.  Fixes Docker startup on Ubuntu with snap-installed Docker where systemctl start docker fails with \"Unit docker.service not found\".  * feat(openclaw): add secure instance overrides and global llm status  * docs: add clarifying comments for PR #161 review findings  - HasAPIKey: name == \"ollama\" — explain why Ollama is always \"has key\" - collectSensitiveData — document in-place mutation contract - promptForCustomProvider — explain why custom endpoints use \"openai\" slot - Default Ollama path — explain why apiKeyValue is safe to inline  * fix(llm): rename APIKeyEnv to EnvVar to fix CodeQL false positive  CodeQL flagged ProviderStatus.APIKeyEnv as sensitive data being logged. The field only stores the env var name (e.g. \"ANTHROPIC_API_KEY\"), not the actual key. Rename to EnvVar to avoid triggering the heuristic.  * chore(llm): bump LLMSpy to v3.0.33-obol.1  Syncs upstream v3.0.33 (nohistory, nostore, provider updates, response_format fix) with Obol smart routing extension.  * Fix obol agent not starting by routing to openclaw under the hood for now  * chore(frontend): pin image tag to v0.1.5  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>  * fix(openclaw): bump llmspy image and fix Anthropic baseUrl  Bump llmspy to v3.0.33-obol.2 which fixes the SQLite \"database is locked\" startup race condition in the writer thread.  Fix Anthropic Direct provider baseUrl: remove /v1 suffix since LiteLLM appends /v1/messages itself, causing double-path 404 errors.  * Order `obol openclaw onboard` the same way we do `obol model configure` (#168)  * Change order of obol openclaw onboard to match obol model configure  * Update openclaw to fix auth bug  * ci: pin actions to commit SHAs and bump to latest versions (#171)  Python 3.9 reached end-of-life (Oct 2025) and is no longer cached on GitHub Actions runners, causing \"candidates is not iterable\" errors in setup-python.  Pin all actions to commit SHAs for supply-chain security: - actions/checkout 34e1148 (v4.3.1) - actions/setup-python a26af69 (v5.6.0, Python 3.12) - azure/setup-helm 1a275c3 (v4.3.1) - helm/chart-testing-action 6ec842c (v2.8.0) - helm/kind-action ef37e7f (v1.14.0)  * Bump to 0.1.3 (#172)  * bump frontend correctly (#173)  * May address stack issues (#174)  ---------  Signed-off-by: JeanDaniel Bussy <jd@obol.tech> Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: JeanDaniel Bussy <SilverSurfer972@gmail.com> Co-authored-by: Aga <agnieszka.skrobot1@gmail.com> Co-authored-by: Claude Opus 4.6 <noreply@anthropic.com>") | last weekFeb 17, 2026 |
| [obolup.sh](https://github.com/ObolNetwork/obol-stack/blob/main/obolup.sh "obolup.sh") | [obolup.sh](https://github.com/ObolNetwork/obol-stack/blob/main/obolup.sh "obolup.sh") | [Change for read skills (](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") [#208](https://github.com/ObolNetwork/obol-stack/pull/208) [)](https://github.com/ObolNetwork/obol-stack/commit/2ec0db6891c7e5d78e9f85962eafbcc20f736248 "Change for read skills (#208)") | 2 hours agoFeb 23, 2026 |
| [renovate.json](https://github.com/ObolNetwork/obol-stack/blob/main/renovate.json "renovate.json") | [renovate.json](https://github.com/ObolNetwork/obol-stack/blob/main/renovate.json "renovate.json") | [Release/pre flight and testing (](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") [#191](https://github.com/ObolNetwork/obol-stack/pull/191) [)](https://github.com/ObolNetwork/obol-stack/commit/270b086f176e61e7b80547a1796618b15f6121a0 "Release/pre flight and testing (#191)  * chore: upgrade pinned dependency versions in obolup.sh  Update dependency versions to latest stable releases: - kubectl: 1.31.0 → 1.35.0 - helm: 3.19.1 → 3.19.4 - helmfile: 1.2.2 → 1.2.3 - k9s: 0.32.5 → 0.50.18 - helm-diff: 3.9.11 → 3.14.1  k3d remains at 5.8.3 (already current).  * feat: replace nginx-ingress with Traefik and Gateway API  Replace nginx-ingress controller with Traefik 38.0.2 using Kubernetes Gateway API for routing. This addresses the nginx-ingress deprecation (end of maintenance March 2026).  Changes: - Remove --disable=traefik from k3d config to use k3s built-in Traefik - Replace nginx-ingress helm release with Traefik 38.0.2 in infrastructure - Configure Gateway API provider with cross-namespace routing support - Add GatewayClass and Gateway resources via Traefik helm chart - Convert all Ingress resources to HTTPRoute format:   - eRPC: /rpc path routing   - obol-frontend: / path routing   - ethereum: /execution and /beacon path routing with URL rewrite   - aztec: namespace-based path routing with URL rewrite   - helios: namespace-based path routing with URL rewrite - Disable legacy Ingress in service helm values  Closes #125  * feat: add monitoring stack and gateway updates  * feat: add cloudflared tunnel for public service exposure  Add Cloudflare Tunnel integration to expose obol-stack services publicly without port forwarding or static IPs. Uses quick tunnel mode for MVP.  Changes: - Add cloudflared Helm chart (internal/embed/infrastructure/cloudflared/) - Add tunnel management package (internal/tunnel/) - Add CLI commands: obol tunnel status/restart/logs - Integrate cloudflared into infrastructure helmfile  The tunnel deploys automatically with `obol stack up` and provides a random trycloudflare.com URL accessible via `obol tunnel status`.  Future: Named tunnel support for persistent URLs (obol tunnel login)  * docs: update CLAUDE.md with new dependency versions  Update documentation to reflect the upgraded dependency versions in obolup.sh. This keeps the documentation in sync with the actual pinned versions used by the bootstrap installer.  * feat(auth): add dashboard auth and nodecore token refresh  * feat(llm): add ollama cloud + llmspy foundation  * docs: note llmspy + ollama cloud default  * chore(llm): use official llmspy image and tcp probes  * docs(okr1): note official llmspy image  * fix(llm): run llmspy via llms entrypoint  * fix(llm): use http probes for llmspy  * feat(stack): add pluggable backend system with native k3s support  Introduce a Backend interface that abstracts cluster lifecycle management, enabling both k3d (Docker-based, default) and k3s (native bare-metal) backends. This is a prerequisite for TEE/Confidential Computing workloads which require direct hardware access that k3d cannot provide.  Changes: - Add Backend interface (Init, Up, Down, Destroy, IsRunning, DataDir) - Extract k3d logic into K3dBackend with backward-compatible fallback - Add K3sBackend with sudo process management, PID tracking, and   API server readiness checks - Convert helmfile.yaml to helmfile.yaml.gotmpl using env vars instead   of .Values references (fixes first-pass template rendering) - Fix eRPC secretEnv type mismatch (map vs string for b64enc) - Fix obol-frontend escaped quotes in gotmpl expressions - Add KUBECONFIG env var to helmfile command for hook compatibility - Add 26 unit tests and 10 integration test scenarios  Closes #134  * test(stack): add test-backend skill for k3d/k3s integration testing  Adds a Claude Code skill (`/test-backend`) with bash scripts that exercise the full backend lifecycle: init, up, kubectl, down, restart, and purge for both k3d and k3s backends.  * fix(stack): prevent process group kill from crashing desktop session  The k3s Down() method was using kill -TERM with a negative PID (process group kill), which could kill unrelated system processes like systemd-logind sharing the same process group as the sudo wrapper. This caused the entire desktop session to crash.  Changes: - Kill only the specific sudo/k3s process, not the process group - Remove unused Setpgid/syscall since we no longer use process groups - Add containerd-shim cleanup fallback for binary-only k3s installs - Add 600s helm timeout for kube-prometheus-stack deployment - Disable admission webhook pre-install hooks that timeout on fresh k3s - Fix flaky test: replace fixed sleep with polling loop for API shutdown  * Add pre-flight port check before cluster creation  When `obol stack up` creates a new cluster, k3d tries to bind host ports 80, 8080, 443, and 8443. If any are already in use, Docker fails with a cryptic error and rolls back the entire cluster.  Add a `checkPortsAvailable()` pre-flight check that probes each required port with `net.Listen` before invoking k3d. On conflict, the error message lists the blocked port(s) and shows a `sudo lsof` command to identify the offending process.  * Track llmspy image releases via Renovate  Add custom regex manager to detect new ObolNetwork/llms releases and auto-bump the image tag in llm.yaml. Follows the same pattern used for obol-stack-front-end and OpenClaw version tracking.  * Replace hardcoded gpt-oss:120b-cloud with dynamic Ollama model detection  The default model gpt-oss:120b-cloud does not exist and caused OpenClaw to deploy with a non-functional model configuration. Instead, query the host's Ollama server for actually available models and use those in the overlay. When no models are pulled, deploy with an empty model list and guide users to `obol model setup` or `ollama pull`.  * Add obol-stack-dev skill, integration tests, and README updates  - Add `obol-stack-dev` skill with full reference docs for LLM   smart-routing through llmspy (architecture, CLI wrappers, overlay   generation, integration testing, troubleshooting) - Add integration tests (`//go:build integration`) that deploy 3   OpenClaw instances through obol CLI verbs and validate inference   through Ollama, Anthropic, and OpenAI via llmspy - Expand README model providers section and add OpenClaw commands  * Add build/test commands and references to CLAUDE.md  Add the standard Claude Code header, a Build/Test/Run Commands section with unit test, integration test, and cluster management instructions, and expand the References section with test files, CI/CD workflows, and the developer skill directory. Fix Go version from 1.21 to 1.25.  * Fix privileged port false-positive in preflight check  On Linux, binding to ports < 1024 requires CAP_NET_BIND_SERVICE. net.Listen(\":80\") returns \"permission denied\" (not \"already in use\") when run as a non-root user, causing a false positive that blocked obol stack up entirely on fresh installs. Skip \"permission denied\" errors in checkPortsAvailable() so the stack starts normally.  * Replace DNS resolver with NM dnsmasq plugin + /etc/hosts fallback  The previous approach used a Docker dnsmasq container + NM bridge + veth slave + systemd-resolved drop-in with DNSOverTLS=opportunistic. This was fragile and had several issues:  - Global DNSOverTLS downgrade affecting all system DNS - Failed on Ubuntu 20.04 (NM < 1.30, no veth support) - Failed on Ubuntu Server (no NetworkManager) - Failed on Debian, openSUSE, RHEL (no systemd-resolved) - apk add on every container start (breaks if CDN unreachable)  New tiered approach:  Tier 1 (Linux + NetworkManager): Use NM's built-in dnsmasq plugin with two config files. No Docker container, no bridge, no veth, no resolved drop-in. Works on Ubuntu 20.04+, Fedora, Debian, Arch, RHEL.  Tier 2 (Linux without NM): Managed /etc/hosts entries per deployment. No wildcard but entries are added/removed as services deploy.  Tier 3 (macOS): Unchanged — /etc/resolver/obol.stack with dnsmasq Docker container on port 5553.  Also adds AddHostEntry/RemoveHostEntry public API called from OpenClaw Sync and Delete for the /etc/hosts fallback path.  Fixes #187  * Remove /etc/hosts fallback — require NM dnsmasq for wildcard DNS  Drop the Tier 2 /etc/hosts fallback from the DNS resolver. Per-host entries don't scale (every new OpenClaw instance needs a new entry) and the UX is poor (requires sudo + manual maintenance).  Now Linux wildcard DNS requires NetworkManager with the dnsmasq plugin. Systems without NM get clear install instructions. This ensures *.obol.stack resolution works for all subdomains without per-instance configuration.  Changes: - resolver.go: Remove all /etc/hosts functions (AddHostEntry,   RemoveHostEntry, hostsEntryExists, etc.) and related constants - resolver_test.go: Remove hosts-related tests - openclaw.go: Remove dns.AddHostEntry/RemoveHostEntry calls from   doSync() and Delete(), drop unused dns import  * Fix DNS: update /etc/resolv.conf to bypass systemd-resolved DoT stub  On Ubuntu (and similar distros) systemd-resolved manages /etc/resolv.conf as a stub at 127.0.0.53. When the user has DNSOverTLS=yes configured, resolved tries TLS to all DNS servers in its global scope — including the local address we were injecting via a resolved.conf.d drop-in. This caused *.obol.stack lookups to be sent to the external DNS server (9.9.9.9) which returns NXDOMAIN, making the stack unreachable.  Fix: after NM restarts in dns=dnsmasq mode, redirect /etc/resolv.conf to /run/NetworkManager/resolv.conf (nameserver 127.0.1.1). Applications then query NM's dnsmasq directly, bypassing systemd-resolved entirely. NM's dnsmasq answers *.obol.stack locally and forwards everything else upstream. This eliminates the DoT conflict on any Linux system.  Also: - Remove the legacy systemd-resolved drop-in (obol-stack.conf) if   present from a prior install, since it's no longer needed. - Restore the stub-resolv.conf symlink on stack teardown (removeNMDnsmasq). - Handle \"dnsmasq files exist but resolv.conf not yet updated\" case so   re-running obol stack up fixes partial installations. - Update IsResolverConfigured() to require both conditions.  * Load .env for integration tests and improve missing-key messages  Integration tests for cloud providers (Anthropic, OpenAI) require API keys. Previously they only read from shell environment variables, giving a generic skip message with no guidance.  - Add TestMain that calls loadDotEnv() before any test runs - loadDotEnv() reads KEY=value pairs from .env at the repo root;   existing shell exports are not overwritten (explicit takes precedence) - requireEnvKey() now shows the exact .env line to add when a key   is missing, pointing to .env.example for reference - Add .env.example documenting ANTHROPIC_API_KEY and OPENAI_API_KEY  * Regenerate helmfile.yaml on default OpenClaw re-sync  The idempotent re-sync path for the default instance was reusing the on-disk helmfile.yaml unchanged. When chartVersion bumped (0.1.0 → 0.1.3), existing installs never picked up the new chart, causing the secrets.gatewayToken.value validation error on obol stack up.  Always regenerate helmfile.yaml before syncing so chart version bumps are applied automatically. values-obol.yaml (user config) is left unchanged.  * Fix PVC permissions for KubeletInUserNamespace k3d clusters  With KubeletInUserNamespace=true, the kubelet cannot apply fsGroup chown to mounted volumes. This caused the extract-skills init container (runAsUser: 1000) to fail with Permission denied on PVC directories created as root:root 0755 by the local-path-provisioner.  Add chown 1000:1000 to the setup script so new PVCs are immediately owned by the app user. Keeps mode 0755 (not world-writable) and only grants access to the specific UID used by all stack applications.  * fix(k3s): resolve sudo, DNS, and disk-pressure issues found on SilverMesh  - backend_k3s: try sudo -n true before sudo -v so NOPASSWD works without TTY - dns/resolver: wait for DNS to respond after NM restart to prevent transient outage - k3s-config: use absolute eviction thresholds (k3s reports imagefs capacity as 0   on shared filesystems, making percentage thresholds always trigger disk-pressure)  * fix(test-backend): add k3s pre-flight checks and PATH fix  - Include /usr/bin:/usr/sbin on PATH (obol calls sudo, nslookup, systemctl) - Pre-flight: check k3s binary exists before running tests - Pre-flight: verify NOPASSWD sudo or cached credentials - SKILL.md: clarify sudo requirement for non-interactive use  * chore(embed): remove stale helmfile.yaml.gotmpl  Superseded by helmfile.yaml which uses Helmfile's native values system instead of Go env-var templates. The .gotmpl variant was never referenced by the Go embed code and contained outdated config (obol-app v0.1.0, missing obol-frontend-rbac, old gateway-api-crds hook).  ---------  Co-authored-by: bussyjd <jd@obol.tech> Co-authored-by: bussyjd <bussyjd@users.noreply.github.com> Co-authored-by: bussyjd <silversurfer972@gmail.com>") | 4 days agoFeb 19, 2026 |
| View all files |

## Repository files navigation

[![Obol banner](https://camo.githubusercontent.com/ffca6da9120089c836bae9ba62cef548478d0183d0e3985a5514f32f78fa065b/68747470733a2f2f6f626f6c2e6f72672f6f626f6c6e6574776f726b2e706e67)](https://camo.githubusercontent.com/ffca6da9120089c836bae9ba62cef548478d0183d0e3985a5514f32f78fa065b/68747470733a2f2f6f626f6c2e6f72672f6f626f6c6e6574776f726b2e706e67)

# The Obol Stack: Where agents deploy their infrastructure

[Permalink: The Obol Stack: Where agents deploy their infrastructure](https://github.com/ObolNetwork/obol-stack#the-obol-stack-where-agents-deploy-their-infrastructure)

## Overview

[Permalink: Overview](https://github.com/ObolNetwork/obol-stack#overview)

The [Obol Stack](https://obol.org/stack) is a framework for AI agents to run decentralised infrastructure locally. It provides an agent with the ability to sync blockchain networks (Ethereum, Aztec, etc.), interact with them via skills, and expose services to the public internet through Cloudflare [tunnels](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) and [x402](https://www.x402.org/) payment gateways.

Built on [Kubernetes](https://kubernetes.io/) with [Helm](https://helm.sh/) for package management. Read more in the [docs](https://docs.obol.org/next/obol-stack/obol-stack).

[![The Obol Stack](https://github.com/ObolNetwork/obol-stack/raw/main/assets/frontend.png)](https://github.com/ObolNetwork/obol-stack/blob/main/assets/frontend.png)

Important

The Obol Stack is alpha software. If you encounter an issue, please open a
[GitHub issue](https://github.com/obolNetwork/obol-stack/issues).

## Getting Started

[Permalink: Getting Started](https://github.com/ObolNetwork/obol-stack#getting-started)

### Prerequisites

[Permalink: Prerequisites](https://github.com/ObolNetwork/obol-stack#prerequisites)

[Docker](https://www.docker.com/) must be installed and running:

- **Linux**: [Docker Engine installation guide](https://docs.docker.com/engine/install/)
- **macOS/Windows**: [Docker Desktop](https://docs.docker.com/desktop/)

### Install

[Permalink: Install](https://github.com/ObolNetwork/obol-stack#install)

```
bash <(curl -s https://stack.obol.org)
```

The installer will set up the `obol` CLI and all dependencies (`kubectl`, `helm`, `k3d`, `helmfile`, `k9s`) into `~/.local/bin/`, configure your PATH, and offer to start the cluster.

Verify:

```
obol version
```

### Quick Start

[Permalink: Quick Start](https://github.com/ObolNetwork/obol-stack#quick-start)

```
# Start the stack
obol stack init
obol stack up

# Set up your AI agent (interactive — choose a model provider)
obol agent init

# Open the agent dashboard
obol openclaw dashboard default
```

The agent init flow will configure [OpenClaw](https://openclaw.ai/) with your chosen model provider (Ollama, Anthropic, or OpenAI) and deploy it to the cluster.

## Blockchain Networks

[Permalink: Blockchain Networks](https://github.com/ObolNetwork/obol-stack#blockchain-networks)

Install and run blockchain networks as isolated deployments. Each installation gets a unique namespace so you can run multiple instances side-by-side.

```
# List available networks
obol network list

# Install a network (generates a unique deployment ID)
obol network install ethereum
# → ethereum-nervous-otter

# Deploy to the cluster
obol network sync ethereum/nervous-otter

# Install another with different config
obol network install ethereum --network=hoodi --execution-client=geth
# → ethereum-happy-panda
obol network sync ethereum/happy-panda
```

**Available networks:** ethereum, aztec

**Ethereum options:**`--network` (mainnet, hoodi), `--execution-client` (reth, geth, nethermind, besu, erigon, ethereumjs), `--consensus-client` (lighthouse, prysm, teku, nimbus, lodestar, grandine)

```
# View installed deployments
obol kubectl get namespaces | grep -E "ethereum|aztec"

# Delete a deployment
obol network delete ethereum/nervous-otter --force
```

Tip

Use `obol network install <network> --help` to see all options.

## Applications

[Permalink: Applications](https://github.com/ObolNetwork/obol-stack#applications)

Install arbitrary Helm charts as managed applications:

```
# Install from ArtifactHub
obol app install bitnami/redis

# With specific version
obol app install bitnami/postgresql@15.0.0

# Deploy to cluster
obol app sync postgresql/eager-fox

# List and manage
obol app list
obol app delete postgresql/eager-fox --force
```

Find charts at [Artifact Hub](https://artifacthub.io/).

## Model Providers

[Permalink: Model Providers](https://github.com/ObolNetwork/obol-stack#model-providers)

The stack runs [llmspy](https://github.com/ObolNetwork/llms) as an in-cluster gateway that proxies all LLM traffic. By default, Ollama on the host machine is used. To switch to a cloud provider:

```
# Interactive — prompts for provider and API key
obol model setup

# Or pass flags directly
obol model setup --provider anthropic --api-key sk-ant-...
obol model setup --provider openai --api-key sk-proj-...

# Check which providers are enabled
obol model status
```

`model setup` patches the llmspy Kubernetes Secret with your API key, enables the provider, and restarts the gateway. All OpenClaw instances automatically route through llmspy.

## OpenClaw AI Agent

[Permalink: OpenClaw AI Agent](https://github.com/ObolNetwork/obol-stack#openclaw-ai-agent)

[OpenClaw](https://openclaw.ai/) is the AI agent deployed by the stack. Multiple instances can run side-by-side, each with its own model provider configuration.

```
# Create and deploy an instance (interactive provider setup)
obol openclaw onboard

# Reconfigure model provider for an existing instance
obol openclaw setup

# List instances
obol openclaw list

# Open the web dashboard
obol openclaw dashboard

# Manage skills (add, remove, list)
obol openclaw skills list
obol openclaw skills add <package>
obol openclaw skills remove <name>

# Remove an instance
obol openclaw delete --force
```

When only one OpenClaw instance is installed, the instance ID is optional — it is auto-selected. With multiple instances, specify the name: `obol openclaw setup prod`.

### Skills

[Permalink: Skills](https://github.com/ObolNetwork/obol-stack#skills)

OpenClaw ships with 20 embedded skills that are installed automatically on first deploy. Skills give the agent domain-specific capabilities — from querying blockchains to understanding Ethereum development patterns.

#### Infrastructure

[Permalink: Infrastructure](https://github.com/ObolNetwork/obol-stack#infrastructure)

| Skill | Purpose |
| --- | --- |
| `ethereum-networks` | Read-only Ethereum queries via cast — blocks, balances, contract reads, ERC-20, ENS |
| `obol-stack` | Kubernetes cluster diagnostics — pods, logs, events, deployments |
| `distributed-validators` | Obol DVT cluster monitoring, operator audit, exit coordination |

#### Ethereum Development

[Permalink: Ethereum Development](https://github.com/ObolNetwork/obol-stack#ethereum-development)

| Skill | Purpose |
| --- | --- |
| `addresses` | Verified contract addresses — DeFi, tokens, bridges, ERC-8004 registries across chains |
| `building-blocks` | OpenZeppelin patterns, DEX integration, oracle usage, access control |
| `concepts` | Mental model — state machines, incentive design, gas mechanics, EOAs vs contracts |
| `gas` | Gas optimization patterns, L2 fee structures, estimation |
| `indexing` | The Graph, Dune, event indexing for onchain data |
| `l2s` | L2 comparison — Base, Arbitrum, Optimism, zkSync with gas costs and use cases |
| `orchestration` | End-to-end dApp build (Scaffold-ETH 2) + AI agent commerce cycle |
| `security` | Smart contract vulnerability patterns, reentrancy, flash loans, MEV protection |
| `standards` | ERC-8004, x402, EIP-3009, EIP-7702, ERC-4337 — spec details and integration patterns |
| `ship` | Architecture planning — onchain vs offchain, chain selection, agent service patterns |
| `testing` | Foundry testing — unit, fuzz, fork, invariant tests |
| `tools` | Development tooling — Foundry, Hardhat, Scaffold-ETH 2, verification |
| `wallets` | Wallet management — EOAs, Safe multisig, EIP-7702, key safety for AI agents |

#### Frontend & QA

[Permalink: Frontend & QA](https://github.com/ObolNetwork/obol-stack#frontend--qa)

| Skill | Purpose |
| --- | --- |
| `frontend-playbook` | Deployment — IPFS, Vercel, ENS subdomains |
| `frontend-ux` | Web3 UX patterns — wallet connection, transaction flows, error handling |
| `qa` | Quality assurance — testing strategy, coverage, CI/CD patterns |
| `why` | Why Ethereum — the AI agent angle with ERC-8004 and x402 |

Manage skills at runtime:

```
obol openclaw skills list                   # list installed skills
obol openclaw skills sync                   # re-inject embedded defaults
obol openclaw skills sync --from ./my-skills  # push custom skills from local dir
obol openclaw skills add <package>          # add via openclaw CLI in pod
obol openclaw skills remove <name>          # remove via openclaw CLI in pod
```

Skills are delivered via host-path PVC injection — no ConfigMap size limits, works before pod readiness, and survives pod restarts.

## Public Access (Cloudflare Tunnel)

[Permalink: Public Access (Cloudflare Tunnel)](https://github.com/ObolNetwork/obol-stack#public-access-cloudflare-tunnel)

Expose your stack to the internet via Cloudflare Tunnel:

```
# Check tunnel status (quick tunnel mode is the default)
obol tunnel status

# Use a persistent hostname
obol tunnel login --hostname stack.example.com

# Or provision via API
obol tunnel provision --hostname stack.example.com \
  --account-id ... --zone-id ... --api-token ...
```

## Managing the Stack

[Permalink: Managing the Stack](https://github.com/ObolNetwork/obol-stack#managing-the-stack)

```
obol stack up        # Start the cluster
obol stack down      # Stop the cluster (preserves data)
obol stack purge -f  # Remove everything (including data)
obol k9s             # Interactive cluster UI
```

The `obol` CLI wraps `kubectl`, `helm`, `helmfile`, and `k9s` with the correct KUBECONFIG:

```
obol kubectl get pods --all-namespaces
obol helm list --all-namespaces
```

## Troubleshooting

[Permalink: Troubleshooting](https://github.com/ObolNetwork/obol-stack#troubleshooting)

#### Port 80 Already in Use

[Permalink: Port 80 Already in Use](https://github.com/ObolNetwork/obol-stack#port-80-already-in-use)

Edit `~/.config/obol/k3d.yaml`, remove the `80:80` and `443:443` port entries (keep `8080:80` and `8443:443`), then restart:

```
obol stack down && obol stack up
```

Access at [http://obol.stack:8080](http://obol.stack:8080/) instead.

## File Locations

[Permalink: File Locations](https://github.com/ObolNetwork/obol-stack#file-locations)

Follows the [XDG Base Directory](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) specification:

| Directory | Purpose |
| --- | --- |
| `~/.config/obol/` | Cluster config, kubeconfig, network and app deployments |
| `~/.local/share/obol/` | Persistent volumes (blockchain data) |
| `~/.local/bin/` | CLI binary and dependencies |

## Updating

[Permalink: Updating](https://github.com/ObolNetwork/obol-stack#updating)

```
bash <(curl -s https://stack.obol.org)
```

The installer detects your existing installation and upgrades safely.

## Uninstalling

[Permalink: Uninstalling](https://github.com/ObolNetwork/obol-stack#uninstalling)

```
obol stack purge -f
rm -f ~/.local/bin/{obol,kubectl,helm,k3d,helmfile,k9s,obolup.sh}
rm -rf ~/.config/obol ~/.local/share/obol
```

## Development

[Permalink: Development](https://github.com/ObolNetwork/obol-stack#development)

```
git clone https://github.com/ObolNetwork/obol-stack.git
cd obol-stack
OBOL_DEVELOPMENT=true ./obolup.sh
```

Development mode uses `.workspace/` instead of XDG directories and runs `go run` on every `obol` invocation — no build step needed.

Networks are embedded at `internal/embed/networks/`. Each uses annotated Go templates that auto-generate CLI flags:

```
# @enum mainnet,hoodi
# @default mainnet
# @description Blockchain network to deploy
network: {{.Network}}
```

See [CONTRIBUTING.md](https://github.com/ObolNetwork/obol-stack/blob/main/CONTRIBUTING.md) for details.

## License

[Permalink: License](https://github.com/ObolNetwork/obol-stack#license)

[Apache License 2.0](https://github.com/ObolNetwork/obol-stack/blob/main/LICENSE)

## About

A Kubernetes-based Ethereum stack for running decentralised applications.


[obol.org/stack](https://obol.org/stack "https://obol.org/stack")

### Topics

[kubernetes](https://github.com/topics/kubernetes "Topic: kubernetes") [helm](https://github.com/topics/helm "Topic: helm") [ethereum](https://github.com/topics/ethereum "Topic: ethereum") [dapp](https://github.com/topics/dapp "Topic: dapp")

### Resources

[Readme](https://github.com/ObolNetwork/obol-stack#readme-ov-file)

### License

[Apache-2.0 license](https://github.com/ObolNetwork/obol-stack#Apache-2.0-1-ov-file)

### Contributing

[Contributing](https://github.com/ObolNetwork/obol-stack#contributing-ov-file)

### Uh oh!

There was an error while loading. [Please reload this page](https://github.com/ObolNetwork/obol-stack).

[Activity](https://github.com/ObolNetwork/obol-stack/activity)

[Custom properties](https://github.com/ObolNetwork/obol-stack/custom-properties)

### Stars

[**4**\\
stars](https://github.com/ObolNetwork/obol-stack/stargazers)

### Watchers

[**3**\\
watching](https://github.com/ObolNetwork/obol-stack/watchers)

### Forks

[**0**\\
forks](https://github.com/ObolNetwork/obol-stack/forks)

[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FObolNetwork%2Fobol-stack&report=ObolNetwork+%28user%29)

## [Releases\  11](https://github.com/ObolNetwork/obol-stack/releases)

[Release v0.3.1\\
Latest\\
\\
3 days agoFeb 20, 2026](https://github.com/ObolNetwork/obol-stack/releases/tag/v0.3.1)

[\+ 10 releases](https://github.com/ObolNetwork/obol-stack/releases)

### Uh oh!

There was an error while loading. [Please reload this page](https://github.com/ObolNetwork/obol-stack).

## [Contributors\  6](https://github.com/ObolNetwork/obol-stack/graphs/contributors)

- [![@Padraic-O-Mhuiris](https://avatars.githubusercontent.com/u/39857859?s=64&v=4)](https://github.com/Padraic-O-Mhuiris)
- [![@bussyjd](https://avatars.githubusercontent.com/u/145845?s=64&v=4)](https://github.com/bussyjd)
- [![@OisinKyne](https://avatars.githubusercontent.com/u/4981644?s=64&v=4)](https://github.com/OisinKyne)
- [![@agaskrobot](https://avatars.githubusercontent.com/u/11446164?s=64&v=4)](https://github.com/agaskrobot)
- [![@claude](https://avatars.githubusercontent.com/u/81847?s=64&v=4)](https://github.com/claude)
- [![@Copilot](https://avatars.githubusercontent.com/in/946600?s=64&v=4)](https://github.com/apps/copilot-pull-request-reviewer)

## Languages

- [Go78.7%](https://github.com/ObolNetwork/obol-stack/search?l=go)
- [Shell11.1%](https://github.com/ObolNetwork/obol-stack/search?l=shell)
- [Python5.1%](https://github.com/ObolNetwork/obol-stack/search?l=python)
- [Go Template3.7%](https://github.com/ObolNetwork/obol-stack/search?l=go-template)
- [Just0.7%](https://github.com/ObolNetwork/obol-stack/search?l=just)
- [JavaScript0.5%](https://github.com/ObolNetwork/obol-stack/search?l=javascript)
- [Nix0.2%](https://github.com/ObolNetwork/obol-stack/search?l=nix)

You can’t perform that action at this time.