import fs from "node:fs/promises";
import path from "node:path";

const ROOT = path.resolve(process.cwd());
const RUNS_DIR = path.join(ROOT, "runs");
const PUBLIC_DIR = path.join(ROOT, "public");

const SOURCES_FILE = path.join(ROOT, "sources.json");

async function loadSources() {
  try {
    const raw = await fs.readFile(SOURCES_FILE, "utf8");
    const parsed = JSON.parse(raw);
    if (Array.isArray(parsed.sources)) return parsed.sources;
  } catch {
    // fall back below
  }
  return [];
}

async function saveSources(sources) {
  const payload = {
    version: 1,
    updatedAt: new Date().toISOString(),
    sources,
  };
  await fs.writeFile(SOURCES_FILE, JSON.stringify(payload, null, 2), "utf8");
}

function isoDate(d = new Date()) {
  return d.toISOString().slice(0, 10);
}

function stripTracking(u) {
  try {
    const url = new URL(u);
    const dropKeys = [
      "utm_source",
      "utm_medium",
      "utm_campaign",
      "utm_term",
      "utm_content",
      "ref",
      "ref_src",
    ];
    for (const k of dropKeys) url.searchParams.delete(k);
    if (url.hash && ["#main", "#maincontent", "#content"].includes(url.hash)) url.hash = "";
    return url.toString();
  } catch {
    return u;
  }
}

function isJunkLink(u) {
  const x = u.toLowerCase();
  if (x.includes("twitter.com/intent")) return true;
  if (x.includes("x.com/intent")) return true;
  if (x.includes("facebook.com/sharer")) return true;
  if (x.includes("reddit.com/submit")) return true;
  if (x.includes("bsky.app/intent")) return true;
  if (x.includes("g.lifehacker.com/")) return true;
  if (x.includes("doubleclick")) return true;
  return false;
}

function extractLinks(html, max = 400) {
  const links = [];
  const re = /href\s*=\s*"([^"]+)"/gi;
  let m;
  while ((m = re.exec(html))) {
    const href = m[1];
    if (!href) continue;
    if (href.startsWith("javascript:")) continue;
    links.push(href);
    if (links.length >= max) break;
  }
  return [...new Set(links)];
}

async function fetchText(url) {
  const res = await fetch(url, {
    headers: {
      "user-agent": "molt-scout/0.1 (+local dashboard)",
      accept: "text/html,application/json;q=0.9,*/*;q=0.8",
    },
  });
  const text = await res.text();
  return { ok: res.ok, status: res.status, text };
}

function parseGitHubRepo(url) {
  try {
    const u = new URL(url);
    if (u.hostname !== "github.com") return null;
    const parts = u.pathname.split("/").filter(Boolean);
    if (parts.length < 2) return null;
    const [owner, repo] = parts;
    // ignore extra paths like /tree/main
    return { owner, repo: repo.replace(/\.git$/i, "") };
  } catch {
    return null;
  }
}

async function fetchGitHubReadme(owner, repo) {
  // Try common default branches without requiring GitHub API.
  const branches = ["main", "master"];
  for (const br of branches) {
    const rawUrl = `https://raw.githubusercontent.com/${owner}/${repo}/${br}/README.md`;
    try {
      const res = await fetch(rawUrl, {
        headers: { "user-agent": "molt-scout/0.1" },
      });
      if (!res.ok) continue;
      const text = await res.text();
      if (text && text.length > 10) return { ok: true, branch: br, text, url: rawUrl };
    } catch {
      // continue
    }
  }
  return { ok: false, branch: null, text: "", url: null };
}

function extractMarkdownHeadings(md, max = 40) {
  const lines = md.split(/\r?\n/);
  const out = [];
  for (const line of lines) {
    const m = /^(#{1,4})\s+(.+?)\s*$/.exec(line);
    if (!m) continue;
    const level = m[1].length;
    const title = m[2].replace(/\s+#+\s*$/, "").trim();
    out.push({ level, title });
    if (out.length >= max) break;
  }
  return out;
}

function extractMarkdownLinks(md, max = 200) {
  const out = [];
  // [text](url)
  const re = /\[[^\]]+\]\((https?:\/\/[^)\s]+)\)/g;
  let m;
  while ((m = re.exec(md))) {
    out.push(m[1]);
    if (out.length >= max) break;
  }
  return [...new Set(out)];
}

async function writeDashboard(latestRun) {
  const community = (latestRun.shortlist || []).filter((u) => {
    const x = u.toLowerCase();
    return x.includes("discord.gg") || x.includes("discord.com/invite") || x.includes("t.me/") || x.includes("telegram");
  });

  const html = `<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MOLT Scout</title>
  <style>
    body{font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Helvetica,Arial;max-width:980px;margin:40px auto;padding:0 16px;}
    code{background:#f5f5f5;padding:2px 6px;border-radius:6px;}
    .card{border:1px solid #e5e5e5;border-radius:12px;padding:16px;margin:12px 0;}
    a{color:#0b5fff;text-decoration:none}
    a:hover{text-decoration:underline}
    .muted{color:#666}
    ul{margin:8px 0 0 18px}
  </style>
</head>
<body>
  <h1>MOLT Scout</h1>
  <p class="muted">Local dashboard generated by a daily scan. Last run: <code>${latestRun.date}</code> (${new Date(latestRun.generatedAt).toLocaleString()})</p>

  <div class="card">
    <h2>Community links (highest priority)</h2>
    <p class="muted">Telegram/Discord links discovered across sources. These are the best candidates to add as first-class sources.</p>
    <ul>
      ${(community.length ? community : ["(none found yet)"])
        .slice(0, 50)
        .map((x) => (x.startsWith("(") ? `<li class=\"muted\">${x}</li>` : `<li><a href=\"${x}\" target=\"_blank\" rel=\"noreferrer\">${x}\"</a></li>`))
        .join("\n")}
    </ul>
  </div>

  <div class="card">
    <h2>Shortlist (scored)</h2>
    <p class="muted">Auto-cleaned + de-duped; sorted by likelihood of being actionable (money/community intent).</p>
    <ul>
      ${(latestRun.shortlist || [])
        .slice(0, 80)
        .map((x) => `<li><a href="${x}" target="_blank" rel="noreferrer">${x}</a></li>`)
        .join("\n")}
    </ul>
  </div>

  ${latestRun.sources
    .map(
      (s) => {
        const parsed = s.parsed;
        const ghBlock =
          parsed && parsed.kind === "github"
            ? `
          <details style="margin-top:10px">
            <summary>Repo summary (README)</summary>
            <div class="muted">branch: <code>${parsed.readmeBranch || "?"}</code> · <a href="${parsed.readmeUrl}" target="_blank" rel="noreferrer">raw README</a></div>
            <div style="margin-top:10px">
              <strong>Headings</strong>
              <ul>
                ${(parsed.headings || [])
                  .slice(0, 20)
                  .map((h) => `<li class="muted">${"&nbsp;".repeat((h.level - 1) * 2)}${h.title}</li>`)
                  .join("\n")}
              </ul>
            </div>
            <div style="margin-top:10px">
              <strong>Key links</strong>
              <ul>
                ${(parsed.links || [])
                  .slice(0, 40)
                  .map((l) => `<li><a href="${l}" target="_blank" rel="noreferrer">${l}</a></li>`)
                  .join("\n")}
              </ul>
            </div>
          </details>
        `
            : "";

        return `
      <div class="card">
        <h2>${s.id}</h2>
        <div class="muted">${s.url} · status ${s.status} · bytes ${s.bytes}</div>
        ${ghBlock}
        <details style="margin-top:10px">
          <summary>Top links (${s.links.length})</summary>
          <ul>
            ${s.links
              .slice(0, 60)
              .map((l) => `<li><a href="${l}" target="_blank" rel="noreferrer">${l}</a></li>`)
              .join("\n")}
          </ul>
        </details>
      </div>
    `;
      },
    )
    .join("\n")}

  <hr />
  <p class="muted">Data file: <a href="./latest.json">latest.json</a></p>
</body>
</html>`;

  await fs.mkdir(PUBLIC_DIR, { recursive: true });
  await fs.writeFile(path.join(PUBLIC_DIR, "index.html"), html, "utf8");
  await fs.writeFile(path.join(PUBLIC_DIR, "latest.json"), JSON.stringify(latestRun, null, 2), "utf8");
}

function scoreLink(u) {
  const x = u.toLowerCase();
  let s = 0;

  // high-value: communities
  if (x.includes("discord.gg") || x.includes("discord.com/invite")) s += 50;
  if (x.includes("t.me/") || x.includes("telegram")) s += 45;
  if (x.includes("reddit.com/r/")) s += 20;

  // money intent
  if (x.includes("trade") || x.includes("alpha") || x.includes("profit") || x.includes("strategy")) s += 15;
  if (x.includes("bot") || x.includes("automation") || x.includes("agent")) s += 10;

  // topic
  if (x.includes("molt")) s += 10;
  if (x.includes("moltbook")) s += 10;
  if (x.includes("openclaw") || x.includes("clawdbot") || x.includes("skill")) s += 6;

  // downrank obvious noise
  if (x.includes("img.shields.io") || x.includes("badge")) s -= 30;
  if (x.includes("favicon")) s -= 10;
  if (x.includes("/static/") || x.includes("_next/")) s -= 10;

  return s;
}

function buildShortlist(allLinks) {
  const cleaned = allLinks
    .map(stripTracking)
    .filter((u) => !isJunkLink(u));

  const uniq = [...new Set(cleaned)];

  // Keep things that look like they're about molt/openclaw + money/community.
  const filtered = uniq.filter((u) => {
    const x = u.toLowerCase();
    const hasTopic = x.includes("molt") || x.includes("moltbook") || x.includes("openclaw") || x.includes("clawdbot") || x.includes("skill");
    const hasIntent =
      x.includes("discord") ||
      x.includes("t.me") ||
      x.includes("telegram") ||
      x.includes("reddit") ||
      x.includes("trade") ||
      x.includes("alpha") ||
      x.includes("profit") ||
      x.includes("bot") ||
      x.includes("strategy") ||
      x.includes("automation");
    return hasTopic && hasIntent;
  });

  filtered.sort((a, b) => scoreLink(b) - scoreLink(a));

  return filtered.slice(0, 250);
}

async function main() {
  const date = isoDate();
  const generatedAt = new Date().toISOString();

  await fs.mkdir(RUNS_DIR, { recursive: true });

  const sourcesOut = [];
  const allLinks = [];

  const sources = await loadSources();
  if (!sources.length) {
    throw new Error(`No sources found. Ensure ${SOURCES_FILE} exists and has a sources[] array.`);
  }

  // Track newly discovered high-confidence community sources to append.
  const discoveredSources = [];

  for (const src of sources) {
    let status = 0;
    let ok = false;
    let text = "";
    let parsed = undefined;

    try {
      const r = await fetchText(src.url);
      status = r.status;
      ok = r.ok;
      text = r.text;
    } catch (e) {
      status = 0;
      ok = false;
      text = String(e);
    }

    const links = src.kind === "web" ? extractLinks(text) : [];

    // Make links absolute-ish for relative ones
    const abs = links.map((l) => {
      try {
        return new URL(l, src.url).toString();
      } catch {
        return l;
      }
    });

    // If this is a GitHub repo, also fetch README.md (raw) and parse it.
    const gh = parseGitHubRepo(src.url);
    if (gh) {
      const readme = await fetchGitHubReadme(gh.owner, gh.repo);
      if (readme.ok) {
        const headings = extractMarkdownHeadings(readme.text);
        const mdLinks = extractMarkdownLinks(readme.text);
        parsed = {
          kind: "github",
          owner: gh.owner,
          repo: gh.repo,
          readmeBranch: readme.branch,
          readmeUrl: readme.url,
          headings,
          links: mdLinks,
        };
        allLinks.push(...mdLinks);
        // Save raw readme for audit
        const safeId = src.id.replace(/[^a-z0-9_-]/gi, "_");
        await fs.writeFile(path.join(RUNS_DIR, `${date}.${safeId}.README.md`), readme.text, "utf8");
      }
    }

    allLinks.push(...abs);

    sourcesOut.push({
      id: src.id,
      url: src.url,
      ok,
      status,
      bytes: text.length,
      links: abs,
      parsed,
      note: src.note,
    });

    // Save raw snapshot for audit
    const safeId = src.id.replace(/[^a-z0-9_-]/gi, "_");
    await fs.writeFile(path.join(RUNS_DIR, `${date}.${safeId}.raw.txt`), text, "utf8");
  }

  const shortlist = buildShortlist(allLinks);

  // Auto-promote high-confidence community links (Discord/Telegram) into sources.json
  // as additional sources to crawl tomorrow.
  const existingUrls = new Set(sources.map((s) => stripTracking(s.url)));
  const communityLinks = shortlist.filter((u) => {
    const x = u.toLowerCase();
    return x.includes("discord.gg") || x.includes("discord.com/invite") || x.includes("t.me/");
  });

  for (const u of communityLinks.slice(0, 10)) {
    const clean = stripTracking(u);
    if (existingUrls.has(clean)) continue;

    const host = (() => {
      try {
        return new URL(clean).hostname.replace(/\./g, "-");
      } catch {
        return "link";
      }
    })();

    const id = `${host}-${Buffer.from(clean).toString("base64url").slice(0, 8)}`;
    discoveredSources.push({ id, kind: "web", url: clean, note: "auto-discovered community link" });
    existingUrls.add(clean);
  }

  const run = {
    date,
    generatedAt,
    sources: sourcesOut,
    shortlist,
    discoveredSources,
  };

  const outPath = path.join(RUNS_DIR, `${date}.json`);
  await fs.writeFile(outPath, JSON.stringify(run, null, 2), "utf8");

  // Persist newly discovered sources (if any)
  if (discoveredSources.length) {
    const merged = [...sources, ...discoveredSources];
    await saveSources(merged);
  }

  await writeDashboard(run);

  console.log(`MOLT scout run complete: ${outPath}`);
  console.log(`Dashboard: ${path.join(PUBLIC_DIR, "index.html")}`);
  if (discoveredSources.length) {
    console.log(`Added ${discoveredSources.length} new sources to ${SOURCES_FILE}`);
  }
}

await main();
